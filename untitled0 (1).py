# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YO16ny21hTwdB2KaaAe_cI9pCzG-OxFM
"""

# Prompt: connect to drive
# This cell mounts your Google Drive to this Colab notebook environment.
# This allows the notebook to access files stored in your Drive.
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Change the current working directory to where the music genre data is located.
# This makes it easier to reference the audio files later without full paths.
# %cd /content/drive/My Drive/TUD/Projects/'Music Genre Classification'/Data/genres_original/
# List the contents of the current directory to verify the genre folders are present.
# %ls

# Import essential libraries for data manipulation, visualization, and audio processing.
import numpy as np           # Numerical computing library
import pandas as pd          # Data manipulation and analysis library
import matplotlib.pyplot as plt  # Plotting library for creating static visualizations
import librosa               # Audio analysis library for music and audio applications
import librosa.display       # Functions for visualizing audio data (e.g., waveforms, spectrograms)
from collections import Counter # Utility for counting hashable objects (not explicitly used here but often useful)

import os
import librosa
import warnings

# Define the root directory where the music genre subfolders are stored.
DATA_DIR = "/content/drive/My Drive/TUD/Projects/Music Genre Classification/Data/genres_original"

# Get a list of all genre names by listing the directories within the DATA_DIR.
# These directory names will serve as our labels for classification.
genres = os.listdir(DATA_DIR)
print("Genres found:", genres)

# Initialize empty lists to store the processed audio data and metadata.
audio_signals = []  # Stores the actual audio time-series data (numpy arrays)
sample_rates = []   # Stores the original sample rate for each audio file
labels = []         # Stores the genre label for each audio file
file_paths = []     # Stores the full path to each audio file

# Loop through each identified genre to load its corresponding audio files.
for genre in genres:
    genre_path = os.path.join(DATA_DIR, genre)
    # Ensure that we are only processing actual directories, not files or hidden items.
    if not os.path.isdir(genre_path):
        continue

    print(f"Loading audio files for genre: {genre}")

    # Iterate through each file within the current genre directory.
    for file in os.listdir(genre_path):
        # We are only interested in '.wav' audio files for this project.
        if file.endswith(".wav"):
            file_path = os.path.join(genre_path, file)

            try:
                # Load the audio file using librosa.load.
                # sr=None ensures that the original sample rate of the audio is preserved.
                signal, sr = librosa.load(file_path, sr=None)

                # Append the loaded data to our lists.
                audio_signals.append(signal)
                sample_rates.append(sr)
                labels.append(genre)
                file_paths.append(file_path)
            except Exception as e:
                # If an audio file fails to load (e.g., corrupted file), log a warning
                # and skip to the next file to prevent the script from crashing.
                warnings.warn(f"Could not load {file_path}: {e}")
                continue  # Move to the next file

# Print the total number of audio files successfully loaded to confirm the dataset size.
print("Total audio files loaded:", len(audio_signals))

import matplotlib.pyplot as plt
import librosa.display

# Let's pick the very first loaded audio signal to visualize its waveform.
# This helps us get a feel for the raw audio data.
idx = 0  # We'll look at the first track loaded.

plt.figure(figsize=(12, 4)) # Set up a nice figure size for better viewing.

# Use librosa's display function to plot the waveform.
# It shows amplitude over time.
librosa.display.waveshow(audio_signals[idx], sr=sample_rates[idx])

# Add a title to the plot so we know what we're looking at.
plt.title(f"Waveform - {labels[idx]}")
plt.xlabel("Time (s)") # Label the x-axis for clarity
plt.ylabel("Amplitude") # Label the y-axis
plt.grid(True) # Add a grid for easier reading of values
plt.tight_layout() # Adjust layout to prevent labels from overlapping
plt.show() # Display the plot.

import pandas as pd

# To get more insights, let's calculate the duration of each audio track.
# We can do this by dividing the number of samples by the sample rate.
durations = [len(x) / sr for x, sr in zip(audio_signals, sample_rates)]

# Now, let's gather all our collected metadata into a neat Pandas DataFrame.
# This makes it super easy to inspect and analyze the dataset.
data = pd.DataFrame({
    "file_path": file_paths,
    "genre": labels,
    "sample_rate": sample_rates,
    "duration_sec": durations
})

# Display the first few rows of our new DataFrame to ensure everything looks correct.
print("First 5 rows of the dataset:")
print(data.head())

# Let's take a quick look at the overall statistics of our dataset.
# First, the total number of tracks we've managed to load.
print("Total tracks loaded into DataFrame:", len(data))

# How many unique music genres do we have? This should be 10 for the GTZAN dataset.
print("Number of unique genres:", data['genre'].nunique())

# And a detailed count of tracks for each genre, to check for class balance.
print("\nTracks per genre (distribution):")
print(data['genre'].value_counts())

import matplotlib.pyplot as plt

# Visualizing the genre distribution helps confirm our dataset's balance.
plt.figure(figsize=(10, 6)) # A reasonable size for a bar chart.

# Plotting the count of each genre.
data['genre'].value_counts().plot(kind='bar', color='skyblue')

# Adding a descriptive title and axis labels.
plt.title("Distribution of Tracks Across Music Genres", fontsize=14)
plt.xlabel("Genre", fontsize=12)
plt.ylabel("Number of Tracks", fontsize=12)

# Rotate x-axis labels for better readability if genre names are long.
plt.xticks(rotation=45, ha='right') # 'ha' means horizontal alignment.
plt.grid(axis='y', linestyle='--', alpha=0.7) # Add a subtle grid
plt.tight_layout() # Adjusts plot to fit into figure area.
plt.show() # Show the plot!

import matplotlib.pyplot as plt

# It's important to check the sample rate consistency across our audio files.
# Let's see the distribution of sample rates.
print("Sample rate distribution across all tracks:")
print(data['sample_rate'].value_counts())

# And a visual representation for quick understanding.
plt.figure(figsize=(8, 5))
data['sample_rate'].value_counts().plot(kind='bar', color='lightcoral')

plt.title("Audio Sample Rate Distribution", fontsize=14)
plt.xlabel("Sample Rate (Hz)", fontsize=12)
plt.ylabel("Count of Tracks", fontsize=12)
plt.xticks(rotation=0) # Sample rates are numbers, usually no need to rotate
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Let's get some basic descriptive statistics for track durations.
# This gives us a quick summary of minimum, maximum, average, etc.
print("Summary statistics for track durations (in seconds):")
print(data['duration_sec'].describe())

# A histogram is great for visualizing the distribution of durations.
plt.figure(figsize=(10, 6))
# We'll use 20 bins to show the spread of durations, with clear edges.
plt.hist(data['duration_sec'], bins=20, edgecolor='black', color='lightgreen')

plt.title("Distribution of Track Durations", fontsize=14)
plt.xlabel("Duration (seconds)", fontsize=12)
plt.ylabel("Number of Tracks", fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout() # Make sure everything fits nicely.
plt.show()

import matplotlib.pyplot as plt

# A box plot helps us compare the duration distribution across different genres.
# This can reveal if certain genres typically have longer or shorter tracks.
plt.figure(figsize=(12, 6)) # A wider figure to accommodate all genres.

# Using pandas' built-in boxplot function for convenience.
# We plot 'duration_sec' and group by 'genre'.
data.boxplot(column='duration_sec', by='genre', grid=False, patch_artist=True, medianprops={'color': 'red'})

# We'll set the main title and remove the automatic super title that pandas adds.
plt.title("Track Duration Distribution by Genre", fontsize=16)
plt.suptitle("")  # Clear the automatic super title for a cleaner look.
plt.xlabel("Music Genre", fontsize=12)
plt.ylabel("Duration (seconds)", fontsize=12)

# Rotate x-axis labels to prevent overlap and improve readability.
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.yticks(fontsize=10)

plt.tight_layout() # Adjust everything to prevent clipping.
plt.show() # Show the comparison plot.

import matplotlib.pyplot as plt
import librosa.display
import librosa
import warnings

# Let's grab the unique genre names and sort them alphabetically for consistent plotting.
genres = sorted(data['genre'].unique())

print("Visualizing waveform examples for each genre...")
# Loop through each genre to display a sample waveform.
for g in genres:
    # Find the first track belonging to the current genre.
    # Using .iloc[0] ensures we get the first entry after filtering.
    row = data[data['genre'] == g].iloc[0]

    # Extract the sample rate and file path for this specific track.
    sr = row['sample_rate']
    file_path = row['file_path']

    try:
        # Load the audio signal using librosa, ensuring the correct sample rate is used.
        signal, _ = librosa.load(file_path, sr=sr)

        # Create a new figure for each waveform to keep plots separate and clear.
        plt.figure(figsize=(10, 3))

        # Plot the waveform using librosa's display utility.
        librosa.display.waveshow(signal, sr=sr, alpha=0.7, color='purple')

        # Add a descriptive title for the current genre's waveform.
        plt.title(f"Waveform Example - {g.capitalize()}", fontsize=14)
        plt.xlabel("Time (s)", fontsize=12)
        plt.ylabel("Amplitude", fontsize=12)
        plt.grid(axis='y', linestyle='--', alpha=0.6)
        plt.tight_layout() # Adjust layout to prevent overlaps.
        plt.show() # Display the plot.
    except Exception as e:
        # If a file cannot be loaded, just print a warning and move on.
        warnings.warn(f"Could not load waveform for {g} from {file_path}: {e}")
        continue

import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
import warnings

# Spectrograms are a powerful way to visualize frequency content over time.
# Let's generate and display mel spectrograms for a few example genres.

print("Generating mel spectrogram examples for the first 4 genres...")
# Iterate through the first few genres for demonstration purposes.
for g in genres[:4]:  # We'll just show the first 4 to keep things concise.
    # Get the first track's data for the current genre.
    row = data[data['genre'] == g].iloc[0]
    sr = row['sample_rate']
    file_path = row['file_path']

    try:
        # Load the audio signal.
        signal, _ = librosa.load(file_path, sr=sr)

        # Create a mel spectrogram: a common representation for audio analysis.
        # n_mels=128 is a standard choice for the number of mel bands.
        # The result 'S' represents power at different frequencies over time.
        S = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=128)

        # Convert the power spectrogram to decibels (log scale) for better visualization.
        # 'ref=np.max' normalizes the spectrogram so the loudest part is 0 dB.
        S_db = librosa.power_to_db(S, ref=np.max)

        # Plotting the mel spectrogram.
        plt.figure(figsize=(10, 5)) # Set a good size for the plot.
        librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='mel', cmap='viridis')

        # Add a title, color bar, and adjust layout.
        plt.title(f"Mel Spectrogram - {g.capitalize()}", fontsize=14)
        plt.colorbar(format='%+2.0f dB') # Color bar shows dB values.
        plt.xlabel("Time (s)", fontsize=12)
        plt.ylabel("Mel Frequency", fontsize=12)
        plt.tight_layout() # Ensure all elements fit nicely.
        plt.show() # Display the spectrogram.
    except Exception as e:
        warnings.warn(f"Could not generate spectrogram for {g} from {file_path}: {e}")
        continue

import os

# It's good practice to check for duplicate entries in our dataset.
# First, let's see if there are any duplicate file paths, which would indicate an error in data collection or loading.
print("Checking for duplicate file paths in the dataset:", data['file_path'].duplicated().sum())

# Sometimes, files might have different paths but the same name if copied.
# Let's extract just the file names and check for duplicates there as well.
data['file_name'] = data['file_path'].apply(lambda x: os.path.basename(x))
print("Checking for duplicate file names:", data['file_name'].duplicated().sum())

# Note: This check only looks at paths/names. For true content duplicates, we'd need to hash file contents, which is done later in the preprocessing step.

import os
import hashlib # For creating file hashes to detect content-based duplicates.
import numpy as np
import librosa
from sklearn.preprocessing import LabelEncoder # To convert genre names to numerical labels.
from sklearn.model_selection import train_test_split # For splitting our dataset.

# Define the root directory where our genre folders are located.
DATA_DIR = "/content/drive/My Drive/TUD/Projects/Music Genre Classification/Data/genres_original"

# --- Audio Parameters ---
# Standard sample rate for audio processing (common in many audio tasks).
TARGET_SR = 22050
# Each track in the GTZAN dataset is approximately 30 seconds long.
TRACK_DURATION = 30.0  # seconds
# Calculate the total number of audio samples for a fixed-length track.
SAMPLES_PER_TRACK = int(TARGET_SR * TRACK_DURATION)

# --- Feature (Log-Mel Spectrogram) Parameters ---
# Number of FFT components, influencing frequency resolution.
N_FFT = 2048
# Number of samples between successive frames, affecting time resolution.
HOP_LENGTH = 512
# Number of Mel bands to generate, determining the mel spectrogram's height.
N_MELS = 128

# --- Segment Parameters ---
# We'll split each 30-second track into smaller, more manageable segments.
# This increases the effective dataset size and can improve model generalization.
SEGMENT_DURATION = 3.0 # We choose 3-second segments.
# Number of samples in each segment.
SEGMENT_SAMPLES = int(TARGET_SR * SEGMENT_DURATION)
# How many segments can we get from one full track? (30s / 3s = 10 segments).
SEGMENTS_PER_TRACK = int(SAMPLES_PER_TRACK / SEGMENT_SAMPLES)

print("Preprocessing parameters initialized.")

import os
import hashlib
import shutil # For moving files, not just deleting.
import warnings # To warn about issues without stopping execution.

print("Starting duplicate file detection and handling...")

# ============================
# 1. Remove duplicate audio files (based on content hash)
# ============================

def file_hash(filepath):
    """Calculates the SHA-256 hash of a file's binary content.
       This is a reliable way to detect identical files, regardless of name or location."""
    hasher = hashlib.sha256()
    # Open the file in binary read mode.
    with open(filepath, "rb") as f:
        # Read the entire file content.
        buf = f.read()
        # Update the hasher with the file's content.
        hasher.update(buf)
    return hasher.hexdigest()


hash_dict = {}       # Stores: content_hash -> first_encountered_file_path
duplicates = []      # List to collect paths of all duplicate files found.

# Traverse through each genre directory to find audio files.
for genre in os.listdir(DATA_DIR):
    genre_path = os.path.join(DATA_DIR, genre)
    # Skip if it's not a directory (e.g., a stray file like 'train.csv').
    if not os.path.isdir(genre_path):
        continue

    # Iterate over files within the current genre folder.
    for f in os.listdir(genre_path):
        # We're only interested in WAV audio files.
        if f.endswith(".wav"):
            fp = os.path.join(genre_path, f)
            h = file_hash(fp) # Compute the hash of the current file.

            # If this hash is new, store it with its file path.
            if h not in hash_dict:
                hash_dict[h] = fp
            else:
                # If the hash already exists, this file is a duplicate.
                duplicates.append(fp)
                warnings.warn(f"Duplicate found: {fp} (original at {hash_dict[h]})")

print("Total duplicate files identified:", len(duplicates))

# --- Safer Handling of Duplicates: Move to Backup Folder ---
# Instead of deleting, which can be irreversible, we'll move them to a backup.
# This allows for recovery if any original files were accidentally moved or identified incorrectly.
DUP_DIR = os.path.join(os.path.dirname(DATA_DIR), "duplicates_backup")
os.makedirs(DUP_DIR, exist_ok=True) # Create the backup directory if it doesn't exist.

for d in duplicates:
    try:
        # Move each duplicate file to the backup directory.
        shutil.move(d, os.path.join(DUP_DIR, os.path.basename(d)))
    except Exception as e:
        warnings.warn(f"Could not move duplicate file {d}: {e}")

print("Identified duplicate files have been moved to:", DUP_DIR)
print("Duplicate handling complete.")

import os
import numpy as np

print("Collecting track-level file paths and labels after duplicate removal...")

# ============================
# 2. Collect track-level file paths and labels
# ============================

file_paths = []    # List to store the full path of each unique audio file.
track_labels = []  # List to store the genre label for each corresponding audio file.

# Get an updated list of genre folders (after potential duplicate moving).
# Sort them for consistency.
genres = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])
print("Active genres found:", genres)

# Loop through each genre to collect its audio files.
for genre in genres:
    genre_path = os.path.join(DATA_DIR, genre)
    # Just a sanity check, though we filtered above.
    if not os.path.isdir(genre_path):
        continue

    # Iterate through each file in the current genre directory.
    for f in os.listdir(genre_path):
        # Ensure we only process actual WAV audio files.
        if f.endswith(".wav"):
            file_paths.append(os.path.join(genre_path, f))
            track_labels.append(genre) # Assign the folder name as the genre label.

# Convert lists to NumPy arrays for easier manipulation and compatibility with scikit-learn.
file_paths = np.array(file_paths)
track_labels = np.array(track_labels)

print("Total unique tracks collected after duplicate removal:", len(file_paths))
print("Track collection complete.")

import numpy as np
from sklearn.model_selection import train_test_split

print("Splitting the dataset into training, validation, and test sets...")

# ============================
# 3. Train / Validation / Test Split (track-wise)
# ============================

# It's crucial to split data at the track level first to avoid data leakage.
# We use 'stratify=track_labels' to ensure each split has a similar proportion of genres.
# This is important for balanced classification performance.

# First split: Separate training data from a temporary set (validation + test).
train_paths, temp_paths, train_labels, temp_labels = train_test_split(
    file_paths,
    track_labels,
    test_size=0.30,             # Allocate 30% of data for the temporary set (validation + test).
    stratify=track_labels,      # Maintain genre distribution.
    random_state=42             # For reproducibility of the split.
)

# Second split: Divide the temporary set into distinct validation and test sets.
# test_size=0.50 means 50% of the temp_paths go to validation, 50% to test.
# This results in 15% validation and 15% test of the *original* dataset.
val_paths, test_paths, val_labels, test_labels = train_test_split(
    temp_paths,
    temp_labels,
    test_size=0.50,             # Half of the temp set for validation, half for testing.
    stratify=temp_labels,       # Maintain genre distribution within this split too.
    random_state=42             # Ensure reproducibility.
)

print("Dataset split summary (number of tracks per split):")
print(f"  Training tracks: {len(train_paths)}")
print(f"  Validation tracks: {len(val_paths)}")
print(f"  Test tracks: {len(test_paths)}")
print("Dataset splitting complete.")

import librosa
import numpy as np
import warnings

print("Defining audio loading and feature extraction functions...")

# ============================
# 4. Audio loading & feature extraction functions
# ============================

def load_fixed_length(path,
                      target_sr=TARGET_SR,       # Use the globally defined target sample rate.
                      track_samples=SAMPLES_PER_TRACK): # Use the globally defined fixed track length.
    """
    Loads an audio file, resamples it to a target sample rate, and then
    pads or trims it to a fixed number of samples. This ensures all inputs
    to the model have a consistent length.

    Args:
        path (str): The file path to the audio track.
        target_sr (int): The sample rate to resample the audio to.
        track_samples (int): The desired fixed number of samples for the track.

    Returns:
        1D numpy array: The processed audio signal, or None if loading fails.
    """
    try:
        # Load the audio file. librosa automatically resamples if 'sr' is specified.
        # If sr=None, it uses the file's original sample rate.
        # In our case, we set it to target_sr to ensure consistency.
        signal, sr = librosa.load(path, sr=target_sr, mono=True) # Ensure mono audio
    except Exception as e:
        # If there's any issue loading the file, print a warning and return None.
        warnings.warn(f"Could not load {path} for feature extraction: {e}")
        return None

    # Handle tracks longer than the desired fixed length by trimming.
    if len(signal) > track_samples:
        signal = signal[:track_samples]
    # Handle tracks shorter than the desired fixed length by zero-padding.
    elif len(signal) < track_samples:
        pad_width = track_samples - len(signal)
        signal = np.pad(signal, (0, pad_width), mode="constant") # Pad with zeros.

    return signal


def extract_mel_segments(signal,
                         sr=TARGET_SR,               # Global target sample rate.
                         n_fft=N_FFT,                # Global FFT window size.
                         hop_length=HOP_LENGTH,      # Global hop length.
                         n_mels=N_MELS,              # Global number of Mel bands.
                         segment_samples=SEGMENT_SAMPLES, # Global segment length in samples.
                         segments_per_track=SEGMENTS_PER_TRACK): # Global number of segments per track.
    """
    Splits a full-track audio signal into fixed-length segments and then
    converts each segment into a standardized log-mel spectrogram. This is
    our main feature extraction step.

    Args:
        signal (np.ndarray): The fixed-length audio signal of a track.
        sr (int): Sample rate of the audio.
        n_fft (int): Window size for FFT.
        hop_length (int): Hop length for spectrogram calculation.
        n_mels (int): Number of Mel frequency bins.
        segment_samples (int): Number of samples per audio segment.
        segments_per_track (int): Expected number of segments to extract.

    Returns:
        np.ndarray: An array of log-mel spectrograms, shaped as
                    (segments_per_track, n_mels, time_frames_per_segment).
    """
    segments = []

    # Iterate to create each segment from the full track.
    for s in range(segments_per_track):
        start = s * segment_samples
        end = start + segment_samples
        segment = signal[start:end]

        # Compute the Mel spectrogram for the current segment.
        mel = librosa.feature.melspectrogram(
            y=segment,
            sr=sr,
            n_fft=n_fft,
            hop_length=hop_length,
            n_mels=n_mels,
        )
        # Convert the power spectrogram to decibels (log scale).
        log_mel = librosa.power_to_db(mel, ref=np.max)

        # Normalize each segment: zero mean and unit variance.
        # This is a common practice to help neural networks converge faster.
        mean = log_mel.mean()
        std = log_mel.std() + 1e-9 # Add a small epsilon to avoid division by zero.
        log_mel = (log_mel - mean) / std

        segments.append(log_mel)

    return np.array(segments)


def paths_to_mel_dataset(paths, labels):
    """
    Processes a list of file paths and their corresponding labels to generate
    a dataset of log-mel spectrogram segments and their (repeated) labels.

    Args:
        paths (list or np.ndarray): List of audio file paths.
        labels (list or np.ndarray): List of genre labels corresponding to the paths.

    Returns:
        (np.ndarray, np.ndarray): A tuple containing:
            - X: All extracted log-mel spectrogram segments.
            - y: Labels for each segment (original track label repeated for each segment).
    """
    X_list, y_list = [], []

    # Process each track individually.
    for path, label in zip(paths, labels):
        signal = load_fixed_length(path)
        # Skip if audio loading failed for this track.
        if signal is None:
            continue

        mel_segments = extract_mel_segments(signal)

        # For each segment extracted from a track, add it to X_list and repeat its label in y_list.
        for seg in mel_segments:
            X_list.append(seg)
            y_list.append(label)

    return np.array(X_list), np.array(y_list)

print("Feature extraction functions defined.")

import numpy as np
import warnings # Ensure warnings are imported if not already

print("Building (X, y) datasets of log-mel spectrogram segments for each split...")

# ============================
# 5. Build datasets (X, y) for each split
# ============================

# Convert the file paths and track labels from our splits into the actual
# log-mel spectrogram features (X) and corresponding segment-level labels (y).

# For the training set:
X_train, y_train = paths_to_mel_dataset(train_paths, train_labels)
# For the validation set:
X_val, y_val = paths_to_mel_dataset(val_paths, val_labels)
# For the test set:
X_test, y_test = paths_to_mel_dataset(test_paths, test_labels)

# Print the shapes of the generated datasets to confirm their dimensions.
# X will be (number_of_segments, n_mels, time_frames_per_segment).
# y will be (number_of_segments,).
print("\nShapes of our prepared datasets (before adding channel dimension for CNNs):")
print(f"  X_train: {X_train.shape}, y_train: {y_train.shape}")
print(f"  X_val:   {X_val.shape}, y_val:   {y_val.shape}")
print(f"  X_test:  {X_test.shape}, y_test:  {y_test.shape}")

print("Dataset building complete. Data is ready for model training.")

from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks, optimizers
import numpy as np
import seaborn as sns

print("Preparing labels and defining utility functions for model training and evaluation...")

# ============================
# Data Preparation for Keras/TensorFlow Models
# ============================

# 1. Encode string labels into integers (0 to num_classes-1).
# This is necessary for 'sparse_categorical_crossentropy' loss in Keras.
label_encoder = LabelEncoder()
# Fit the encoder on all labels to ensure all unique genres are mapped consistently.
label_encoder.fit(np.concatenate([y_train, y_val, y_test]))

y_train_enc = label_encoder.transform(y_train)
y_val_enc   = label_encoder.transform(y_val)
y_test_enc  = label_encoder.transform(y_test)

# Create a mapping from encoded integer to original genre name for later interpretation.
idx_to_genre = {i: g for i, g in enumerate(label_encoder.classes_)}
print("\nLabel mapping (integer to genre):", idx_to_genre)

# 2. Add a channel dimension for CNN-based models (e.g., CRNN).
# Keras Conv2D layers expect input shape like (batch, height, width, channels).
# Our current X is (num_segments, n_mels, time_frames), so we add a last dimension of 1.
X_train_cnn = X_train[..., np.newaxis]
X_val_cnn   = X_val[..., np.newaxis]
X_test_cnn  = X_test[..., np.newaxis]

print("\nShapes after adding channel dimension for CNN input:")
print(f"  X_train_cnn: {X_train_cnn.shape}, y_train_enc: {y_train_enc.shape}")
print(f"  X_val_cnn:   {X_val_cnn.shape}, y_val_enc:   {y_val_enc.shape}")
print(f"  X_test_cnn:  {X_test_cnn.shape}, y_test_enc:  {y_test_enc.shape}")

# 3. Update global variables derived from data.
num_classes = len(label_encoder.classes_) # Total number of unique genres.
input_shape = X_train_cnn.shape[1:]     # Input shape for the model (n_mels, time_frames, 1).


# =========================================================================
# Utility functions for Keras model compilation, training, and evaluation
# =========================================================================

def compile_model(model, lr=1e-3):
    """
    Compiles a Keras model with the Adam optimizer, sparse categorical crossentropy loss,
    and accuracy as the metric.

    Args:
        model (tf.keras.Model): The Keras model to compile.
        lr (float): Initial learning rate for the Adam optimizer.

    Returns:
        tf.keras.Model: The compiled Keras model.
    """
    print(f"Compiling model with Adam optimizer (LR={lr}) and sparse_categorical_crossentropy loss.")
    model.compile(
        optimizer=optimizers.Adam(learning_rate=lr),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
    )
    return model

def train_model(model, model_name, X_train, y_train, X_val, y_val, batch_size=32, epochs=50):
    """
    Trains a Keras model using provided data, validation set, and includes callbacks
    for early stopping and saving the best model based on validation accuracy.

    Args:
        model (tf.keras.Model): The Keras model to train.
        model_name (str): A name for the model, used for saving checkpoints.
        X_train (np.ndarray): Training features.
        y_train (np.ndarray): Training labels (encoded).
        X_val (np.ndarray): Validation features.
        y_val (np.ndarray): Validation labels (encoded).
        batch_size (int): Number of samples per gradient update.
        epochs (int): Maximum number of training epochs.

    Returns:
        (tf.keras.Model, tf.keras.callbacks.History): The best trained model and its training history.
    """
    print(f"\nInitiating training for {model_name}...")

    # Callbacks help manage the training process.
    # EarlyStopping: Stops training if validation accuracy doesn't improve for 'patience' epochs.
    early_stopping = callbacks.EarlyStopping(
        monitor="val_accuracy", patience=10, restore_best_weights=True, verbose=1
    )
    # ModelCheckpoint: Saves the model with the best validation accuracy.
    model_checkpoint = callbacks.ModelCheckpoint(
        f"{model_name}_best_model.h5", # File path to save the model.
        monitor="val_accuracy",
        save_best_only=True,         # Only save when validation accuracy improves.
        verbose=0,                   # Suppress verbose output for each save.
    )

    # Fit the model to the training data.
    history = model.fit(
        X_train,
        y_train,
        validation_data=(X_val, y_val),
        batch_size=batch_size,
        epochs=epochs,
        callbacks=[early_stopping, model_checkpoint], # Apply our defined callbacks.
        verbose=1, # Show progress for each epoch.
    )

    # Load the best model saved by the ModelCheckpoint callback.
    best_model = models.load_model(f"{model_name}_best_model.h5")
    print(f"Training for {model_name} finished. Best model loaded from checkpoint.")
    return best_model, history

def evaluate_model(model, X_test, y_test, idx_to_genre, title_suffix=""):
    """
    Evaluates a trained Keras model on the test set, prints a classification report,
    and visualizes the confusion matrix.

    Args:
        model (tf.keras.Model): The trained Keras model.
        X_test (np.ndarray): Test features.
        y_test (np.ndarray): Test labels (encoded).
        idx_to_genre (dict): Mapping from integer label to genre name.
        title_suffix (str): Optional suffix for plot titles.

    Returns:
        (float, float): Test loss and test accuracy.
    """
    print(f"\nEvaluating model{title_suffix} on the test set...")

    # Get the test loss and accuracy.
    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"  Test Loss: {loss:.4f}")
    print(f"  Test Accuracy: {accuracy:.4f}")

    # Predict probabilities for the test set.
    y_pred_probs = model.predict(X_test, verbose=0)
    # Convert probabilities to class predictions (the class with the highest probability).
    y_pred = np.argmax(y_pred_probs, axis=1)

    # Display a comprehensive classification report.
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=list(idx_to_genre.values())))

    # Visualize the confusion matrix to see per-class performance.
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        cm,
        annot=True, # Show the numbers in the cells.
        fmt="d",    # Format numbers as integers.
        cmap="Blues", # Color map for the heatmap.
        xticklabels=list(idx_to_genre.values()), # Label x-axis with genre names.
        yticklabels=list(idx_to_genre.values()), # Label y-axis with genre names.
    )
    plt.title(f"Confusion Matrix{title_suffix}", fontsize=16)
    plt.xlabel("Predicted Label", fontsize=12)
    plt.ylabel("True Label", fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    return loss, accuracy

print("Utility functions for model operations are now defined.")

import tensorflow as tf
from tensorflow.keras import layers, models # Explicitly import models

print("Defining the CRNN (Convolutional Recurrent Neural Network) model architecture...")

# =========================================================================
# Custom Layer/Function: to_sequence
# This function reshapes the output of the CNN layers into a sequence format
# suitable for Recurrent Neural Networks (like LSTMs or GRUs).
# We register it to ensure the Keras model can be saved and loaded properly.
# =========================================================================
@tf.keras.utils.register_keras_serializable()
def to_sequence(tensor):
    """
    Converts a 4D tensor (batch, height, width, channels) from a CNN output
    into a 3D tensor (batch, sequence_length, features) suitable for an RNN.
    Here, 'width' (time dimension of spectrogram) becomes the sequence_length,
    and 'height * channels' combine to form the features for each time step.

    Args:
        tensor (tf.Tensor): Input tensor from CNN output, typically (batch, n_mels, time_frames, 1).

    Returns:
        tf.Tensor: Reshaped tensor, (batch, time_steps, features).
    """
    # Input tensor shape: (batch_size, n_mels_after_conv, time_frames_after_conv, channels)

    # Transpose the tensor to bring the 'time' dimension (width) to the second position.
    # This changes (batch, H, W, C) to (batch, W, H, C).
    tensor = tf.transpose(tensor, perm=[0, 2, 1, 3])

    # Dynamically get the shape components.
    shape = tf.shape(tensor)
    batch_size = shape[0]
    time_steps = shape[1] # 'W' is now our sequence length.
    features = shape[2] * shape[3] # 'H * C' is the feature vector for each time step.

    # Reshape the tensor into (batch_size, time_steps, features).
    return tf.reshape(tensor, [batch_size, time_steps, features])


# =========================================================================
# CRNN Model Definition
# =========================================================================
def build_crnn_model(input_shape, num_classes):
    """
    Constructs a Convolutional Recurrent Neural Network (CRNN) model.
    This model combines Convolutional Neural Network (CNN) layers for feature extraction
    from spectrograms with Recurrent Neural Network (RNN) layers (Bi-LSTM here)
    to model temporal dependencies.

    Args:
        input_shape (tuple): The shape of the input data (n_mels, time_frames, 1).
        num_classes (int): The total number of output classes (genres).

    Returns:
        tf.keras.models.Model: The compiled Keras CRNN model.
    """
    inputs = tf.keras.layers.Input(shape=input_shape)  # Define the input layer with the spectrogram shape.

    # --- CNN Feature Extractor --- #
    # These layers extract spatial features (patterns in frequency and time) from the spectrogram.
    # Block 1
    x = tf.keras.layers.Conv2D(32, (3, 3), padding="same", name="conv1")(inputs)
    x = tf.keras.layers.BatchNormalization(name="bn1")(x) # Normalizes activations, helps training.
    x = tf.keras.layers.Activation("relu", name="relu1")(x)
    x = tf.keras.layers.MaxPooling2D((2, 2), name="pool1")(x) # Reduces spatial dimensions.
    x = tf.keras.layers.Dropout(0.25, name="drop1")(x) # Prevents overfitting.

    # Block 2
    x = tf.keras.layers.Conv2D(64, (3, 3), padding="same", name="conv2")(x)
    x = tf.keras.layers.BatchNormalization(name="bn2")(x)
    x = tf.keras.layers.Activation("relu", name="relu2")(x)
    x = tf.keras.layers.MaxPooling2D((2, 2), name="pool2")(x)
    x = tf.keras.layers.Dropout(0.30, name="drop2")(x)

    # Block 3
    x = tf.keras.layers.Conv2D(128, (3, 3), padding="same", name="conv3")(x)
    x = tf.keras.layers.BatchNormalization(name="bn3")(x)
    x = tf.keras.layers.Activation("relu", name="relu3")(x)
    x = tf.keras.layers.MaxPooling2D((2, 2), name="pool3")(x)
    x = tf.keras.layers.Dropout(0.35, name="drop3")(x)

    # --- Reshape for RNN --- #
    # Convert the 4D CNN output feature map into a 3D sequence of features for the RNN.
    # The 'to_sequence' function handles this transformation.
    x = tf.keras.layers.Lambda(to_sequence, name="to_sequence_layer")(x) # (batch, time_steps, features)

    # --- Recurrent Neural Network (Bi-LSTM) --- #
    # A Bidirectional LSTM processes the sequence in both forward and backward directions,
    # capturing more context and temporal dependencies.
    x = tf.keras.layers.Bidirectional(
        tf.keras.layers.LSTM(128, return_sequences=False), # LSTM units with 128 hidden states. return_sequences=False means only output the last state.
        name="bi_lstm")(x)
    x = tf.keras.layers.Dropout(0.5, name="drop_lstm")(x) # More dropout after the LSTM.

    # --- Classification Head --- #
    # Dense layers for final classification based on the extracted features.
    x = tf.keras.layers.Dense(128, activation="relu", name="dense_pre_output")(x)
    x = tf.keras.layers.Dropout(0.5, name="drop_dense")(x)
    # Output layer with 'softmax' activation for multi-class classification probabilities.
    outputs = tf.keras.layers.Dense(num_classes, activation="softmax", name="output_softmax")(x)

    # Create the model by specifying inputs and outputs.
    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name="CRNN")
    return model

# Instantiate and print a summary of the CRNN model to see its layers and parameters.
crnn_model = build_crnn_model(input_shape, num_classes)
print("\nCRNN Model Summary:")
crnn_model.summary()
print("CRNN model architecture defined.")

# ========================================================
# 1. Compile CRNN model
# ========================================================
# First, we need to compile our CRNN model, specifying the optimizer, loss function, and metrics.
# We'll use the Adam optimizer and sparse_categorical_crossentropy as our loss, as our labels are integers.
crnn_model = compile_model(crnn_model, lr=1e-3)

# ========================================================
# 2. Define NEW callbacks (save to Google Drive)
# ========================================================
# Callbacks are special functions that run during training (at the beginning, end of epochs, etc.).
# They help us manage the training process, like stopping early or saving the best model.

drive_model_path = "/content/drive/My Drive/TUD/Projects/Music Genre Classification/best_crnn_model.keras"

# EarlyStopping: This callback monitors a metric (like validation loss) and stops training
# if it doesn't improve after a certain number of epochs (patience). This prevents overfitting.
early_stopping_cb = callbacks.EarlyStopping(
    monitor="val_loss",       # Monitor the validation loss
    patience=7,               # Wait for 7 epochs for improvement before stopping
    restore_best_weights=True, # Keep the weights from the best performing epoch
    verbose=1                 # Show messages when stopping or restoring weights
)

# ModelCheckpoint: This callback saves the model's weights during training.
# We'll configure it to save only the *best* model based on validation accuracy.
model_checkpoint_cb = callbacks.ModelCheckpoint(
    filepath=drive_model_path, # Path where the best model will be saved
    monitor="val_accuracy",    # Monitor validation accuracy
    save_best_only=True,       # Only save the model if validation accuracy improves
    save_weights_only=False,   # Save the entire model (architecture + weights)
    verbose=1                  # Show messages when a new best model is saved
)

# ReduceLROnPlateau: This callback reduces the learning rate when a metric (val_loss)
# has stopped improving. This can help the model converge better in later stages.
reduce_lr_cb = callbacks.ReduceLROnPlateau(
    monitor="val_loss",      # Monitor validation loss
    factor=0.5,                # Reduce learning rate by a factor of 0.5
    patience=3,                # Wait for 3 epochs without improvement before reducing
    min_lr=1e-6,               # Don't let the learning rate go below this value
    verbose=1                  # Show messages when learning rate is reduced
)

# Combine all our chosen callbacks into a list for the model.fit() function.
crnn_callbacks = [early_stopping_cb, model_checkpoint_cb, reduce_lr_cb]

# ========================================================
# 3. Train CRNN with early stopping + save best model
# ========================================================
# Now, let's train our CRNN model using the prepared data and the callbacks.
# We'll train for a maximum of 60 epochs, but early stopping might stop it sooner.
print("\nStarting CRNN model training...")
crnn_history = crnn_model.fit(
    X_train_cnn,              # Training features (mel spectrograms with channel dim)
    y_train_enc,              # Encoded training labels
    validation_data=(X_val_cnn, y_val_enc), # Validation set for monitoring performance
    epochs=60,                # Maximum number of training epochs
    batch_size=32,            # Number of samples per gradient update
    callbacks=crnn_callbacks, # Our list of callbacks
    verbose=1                 # Show progress for each epoch
)
print("CRNN model training complete.")

# ========================================================
# 4. Load best model from Google Drive
# ========================================================
# After training, we load the best version of the model that was saved by ModelCheckpoint.
# This ensures we're using the model that performed best on the validation set.
print(f"\nLoading the best CRNN model from: {drive_model_path}")
crnn_best = tf.keras.models.load_model(drive_model_path)
print("Best CRNN model loaded successfully.")

# ========================================================
# 5. Evaluate CRNN best model
# ========================================================
# Finally, we evaluate the best CRNN model on our unseen test set
# to get a final, unbiased assessment of its performance.
crnn_test_loss, crnn_test_acc = evaluate_model(
    crnn_best,                 # The best trained CRNN model
    X_test_cnn,                # Test features
    y_test_enc,                # Encoded test labels
    idx_to_genre=idx_to_genre, # Mapping to show genre names in report
    title_suffix=" (CRNN)"    # Suffix for plot titles
)

print("\nCRNN test accuracy:", crnn_test_acc)
print("Best CRNN model saved at:", drive_model_path)

#Option B – CRNN (CNN + Bi-LSTM / GRU)

import os
import copy # Useful for deep copying model states, often used for saving best models.
import numpy as np
import torch # The main PyTorch library.
import torch.nn as nn # Neural network modules and layers for PyTorch.
from torch.utils.data import Dataset, DataLoader # Tools for handling datasets and creating data loaders.
from sklearn.preprocessing import LabelEncoder # For converting categorical labels to numerical ones.
from sklearn.metrics import classification_report, confusion_matrix # For evaluating model performance.
import matplotlib.pyplot as plt # For plotting confusion matrices and other visualizations.

# If your target labels (y_train, y_val, y_test) are text values like music genres,
# they must be converted into numbers before training a neural network.

# Create a LabelEncoder object.
# LabelEncoder assigns a unique integer to each unique string label.
# Example: 'jazz' → 0, 'rock' → 1, 'classical' → 2
le = LabelEncoder()

# Fit the encoder using ALL labels from training, validation, and test sets.
# This guarantees that the same genre always maps to the same number
# across all datasets and avoids mismatches later.
le.fit(np.concatenate([y_train, y_val, y_test]))

# Convert string labels into their numeric (encoded) form.
y_train_enc = le.transform(y_train)
y_val_enc   = le.transform(y_val)
y_test_enc  = le.transform(y_test)

# Create a reverse lookup dictionary:
# numeric label → original genre name.
# This is very useful when analyzing predictions or confusion matrices.
idx_to_genre = {i: g for i, g in enumerate(le.classes_)}

# Count how many unique genres/classes exist.
# This value is typically used to define the size of the model's output layer.
num_classes = len(le.classes_)

# Display the label mapping for verification.
print("Classes:", idx_to_genre)

# Convert feature arrays to float32.
# Neural networks expect floating-point numbers, and float32 is standard
# for better performance and lower memory usage.
X_train_np = X_train.astype(np.float32)
X_val_np   = X_val.astype(np.float32)

class MelDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.from_numpy(X)              # (N, n_mels, time)
        self.y = torch.from_numpy(y).long()       # (N,)

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        x = self.X[idx]   # (n_mels, time)
        y = self.y[idx]
        return x, y

batch_size = 32

train_ds = MelDataset(X_train_np, y_train_enc)
val_ds   = MelDataset(X_val_np,   y_val_enc)
test_ds  = MelDataset(X_test_np,  y_test_enc)

train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)

class CRNN_BiGRU(nn.Module):
    """
    A Convolutional Recurrent Neural Network (CRNN) using Bidirectional GRU layers.
    This architecture is designed to capture both local spatial features (CNN) and
    long-range temporal dependencies (Bi-GRU) from Mel-spectrograms.
    """
    def __init__(self, num_classes):
        super().__init__()

        # --- CNN Feature Extractor ---
        # This sequential block applies a series of 2D convolutional layers,
        # batch normalization, ReLU activation, max-pooling, and dropout.
        # Each block extracts features at different scales and reduces spatial dimensions.
        self.cnn = nn.Sequential(
            # Block 1
            nn.Conv2d(1, 32, kernel_size=3, padding=1), # Input channel 1 (for spectrogram), 32 output channels
            nn.BatchNorm2d(32), # Normalizes activations across batch, stabilizes training
            nn.ReLU(), # Non-linear activation function
            nn.MaxPool2d((2, 2)), # Downsamples feature maps, makes model robust to small shifts
            nn.Dropout(0.25), # Randomly sets a fraction of inputs to zero to prevent overfitting

            # Block 2
            nn.Conv2d(32, 64, kernel_size=3, padding=1), # Input from previous block's output channels
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d((2, 2)),
            nn.Dropout(0.30),

            # Block 3
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d((2, 2)),
            nn.Dropout(0.35),
        )

        # --- Recurrent Neural Network (Bi-GRU) ---
        # The GRU layer will be initialized dynamically once the CNN's output shape is known.
        # It processes the sequence of features extracted by the CNN.
        self.gru = None # Placeholder for GRU, to be built in forward pass

        # --- Classifier Head ---
        # This sequential block takes the output from the GRU and maps it to class probabilities.
        # It includes dropout for regularization and a linear layer for final classification.
        self.classifier = nn.Sequential(
            nn.Dropout(0.5), # More dropout to combat overfitting
            nn.Linear(256, 128),   # Placeholder: input dim 256 for BiGRU (2*128), output 128
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, num_classes) # Final linear layer maps to the number of genre classes
        )

    def _build_gru_if_needed(self, x):
        """
        Dynamically builds the GRU layer based on the actual output shape of the CNN.
        This ensures the input_size for GRU matches the flattened feature dimension per time step.
        """
        # x is the output of the CNN: (batch_size, num_cnn_channels, feature_map_height, feature_map_width)
        b, c, h, w = x.shape
        feat_dim = c * h # The feature dimension for each time step in the sequence
        if self.gru is None:
            # Initialize Bi-GRU:
            # input_size: flattened feature dimension from CNN output.
            # hidden_size: number of features in the hidden state (128 for each direction).
            # num_layers: number of recurrent layers.
            # batch_first=True: input/output tensors are (batch, sequence, feature).
            # bidirectional=True: process sequence in both forward and backward directions.
            self.gru = nn.GRU(
                input_size=feat_dim,
                hidden_size=128,
                num_layers=1,
                batch_first=True,
                bidirectional=True
            ).to(x.device) # Move GRU to the same device as the input tensor
            # Update the first Linear layer in the classifier with the correct input dimension
            # (2 * hidden_size because of bidirectional GRU).
            self.classifier[1] = nn.Linear(2 * 128, 128).to(x.device)

    def forward(self, x):
        """
        Defines the forward pass of the CRNN model.

        Args:
            x (torch.Tensor): Input tensor, typically a batch of Mel-spectrograms
                              with shape (batch_size, n_mels, time_frames).

        Returns:
            torch.Tensor: Logits (raw scores) for each class, shape (batch_size, num_classes).
        """
        # Input x: (batch_size, n_mels, time_frames)
        # Add a channel dimension for the CNN (expected: (batch, channels, H, W)).
        x = x.unsqueeze(1)         # Result: (batch, 1, n_mels, time_frames)
        x = self.cnn(x)            # Pass through CNN. Result: (batch, C_cnn, H_cnn, W_cnn)

        # Dynamically build GRU if it hasn't been built yet (first forward pass).
        self._build_gru_if_needed(x)

        # Reshape CNN output for GRU input.
        # Get current dimensions of CNN output.
        b, c, h, w = x.shape
        # Permute dimensions to (batch, W_cnn, C_cnn, H_cnn) to make W_cnn the sequence length.
        x = x.permute(0, 3, 1, 2).contiguous()
        # Flatten (C_cnn, H_cnn) into a single feature dimension for each time step (W_cnn).
        x = x.view(b, w, c * h)                    # Result: (batch, time_steps, features)

        # Pass through the Bidirectional GRU layer.
        # out: (batch, time_steps, 2*hidden_size), _: hidden state
        out, _ = self.gru(x)
        # Take the output from the *last* time step for classification.
        # The `return_sequences=False` equivalent for GRU is usually taking the last output.
        out = out[:, -1, :]                        # Result: (batch, 2*hidden_size)

        # Pass through the classifier head to get final logits.
        logits = self.classifier(out)              # Result: (batch, num_classes)
        return logits

# Determine which device (GPU or CPU) to use for training based on availability.
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# Initialize the CRNN_BiGRU model and move it to the selected device.
model = CRNN_BiGRU(num_classes=num_classes).to(device)

# Define the loss function: CrossEntropyLoss is suitable for multi-class classification.
criterion = nn.CrossEntropyLoss()

# Define the optimizer: Adam is a popular choice for deep learning, with a specified learning rate.
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# Define the path where the best performing model's weights will be saved.
save_path = "/content/drive/My Drive/TUD/Projects/Music Genre Classification/best_crnn_bigru_pytorch.pt"

# --- Early Stopping Parameters ---
# Patience: Number of epochs to wait for improvement before stopping.
patience = 7
# best_val_acc: Keeps track of the highest validation accuracy achieved so far.
best_val_acc = 0.0
# epochs_no_improve: Counter for epochs without validation accuracy improvement.
epochs_no_improve = 0
# best_state: Stores a deep copy of the model's state (weights) when it achieves best_val_acc.
best_state = None

def run_epoch(loader, train=True):
    """
    Runs a single training or validation/test epoch.

    Args:
        loader (DataLoader): The data loader for the current phase (train, val, or test).
        train (bool): If True, the model is in training mode (gradients computed, weights updated).
                      If False, the model is in evaluation mode (no gradient computation).

    Returns:
        tuple: (average_loss_per_sample, average_accuracy_per_sample) for the epoch.
    """
    # Set model to training or evaluation mode.
    if train:
        model.train()
    else:
        model.eval()

    total_loss = 0.0 # Accumulator for total loss across the epoch.
    correct = 0      # Accumulator for correctly predicted samples.
    total = 0        # Accumulator for total samples processed.

    # torch.set_grad_enabled(train) context manager enables/disables gradient calculations.
    # Gradients are only needed during training.
    with torch.set_grad_enabled(train):
        for xb, yb in loader:
            # Move input features (xb) and labels (yb) to the selected device (GPU/CPU).
            # non_blocking=True allows asynchronous GPU transfers.
            xb = xb.to(device, non_blocking=True)
            yb = yb.to(device, non_blocking=True)

            # Perform a forward pass to get model's predictions (logits).
            logits = model(xb)
            # Calculate the loss between predicted logits and true labels.
            loss = criterion(logits, yb)

            if train:
                # Zero out previous gradients before computing new ones.
                optimizer.zero_grad()
                # Perform backpropagation to compute gradients.
                loss.backward()
                # Update model's weights using the optimizer.
                optimizer.step()

            # Accumulate loss: multiply by batch size to get total loss for batch, then add to total.
            total_loss += loss.item() * xb.size(0)
            # Get predicted class by finding the index of the max logit.
            preds = torch.argmax(logits, dim=1)
            # Count correct predictions.
            correct += (preds == yb).sum().item()
            # Add current batch size to total samples.
            total += xb.size(0)

    # Return average loss and average accuracy for the epoch.
    return total_loss / total, correct / total

# Define the total number of epochs for training.
num_epochs = 60

print("\nStarting PyTorch CRNN Bi-GRU model training...")
# --- Main Training Loop ---
for epoch in range(1, num_epochs + 1):
    # Run one training epoch.
    train_loss, train_acc = run_epoch(train_loader, train=True)
    # Run one validation epoch.
    val_loss, val_acc     = run_epoch(val_loader, train=False)

    # Print epoch results.
    print(f"Epoch {epoch:02d}/{num_epochs} "
          f"train_loss={train_loss:.4f} train_acc={train_acc:.4f} "
          f"val_loss={val_loss:.4f} val_acc={val_acc:.4f}")

    # --- Save Best Model Logic ---
    # If current validation accuracy is better than the best seen so far:
    if val_acc > best_val_acc:
        best_val_acc = val_acc # Update best validation accuracy.
        # Save a deep copy of the model's current state (weights and biases).
        best_state = copy.deepcopy(model.state_dict())
        torch.save(best_state, save_path) # Save the state dictionary to file.
        print(f"  Saved best model to: {save_path}")
        epochs_no_improve = 0 # Reset early stopping counter.
    else:
        epochs_no_improve += 1 # Increment counter if no improvement.

    # --- Early Stopping Check ---
    # If no improvement for 'patience' number of epochs, stop training.
    if epochs_no_improve >= patience:
        print(f"Early stopping triggered. Best val_acc={best_val_acc:.4f}")
        break # Exit the training loop.

# Load the best performing model's weights after the training loop has finished.
model.load_state_dict(torch.load(save_path, map_location=device))
print("Loaded best model from:", save_path)
print("PyTorch CRNN Bi-GRU model training complete.")

# Set the model to evaluation mode. This disables dropout and batch normalization updates.
model.eval()

# Initialize lists to store all predictions and true labels from the test set.
all_preds = []
all_true = []

# Disable gradient calculations during evaluation to save memory and speed up computation.
with torch.no_grad():
    # Iterate over the test data loader.
    for xb, yb in test_loader:
        # Move the input features (xb) to the appropriate device (GPU/CPU).
        xb = xb.to(device, non_blocking=True)

        # Perform a forward pass to get the model's predictions (logits).
        logits = model(xb)
        # Get the predicted class by finding the index of the maximum logit, then move to CPU and convert to NumPy.
        preds = torch.argmax(logits, dim=1).cpu().numpy()

        # Append the predictions and true labels (converted to NumPy) to their respective lists.
        all_preds.append(preds)
        all_true.append(yb.numpy())

# Concatenate all predictions and true labels from batches into single NumPy arrays.
y_pred = np.concatenate(all_preds)
y_true = np.concatenate(all_true)

# Calculate the overall test accuracy.
test_acc = (y_pred == y_true).mean()
print(f"Test Accuracy (PyTorch CRNN Bi-GRU): {test_acc:.4f}")

# Prepare target names for the classification report using our idx_to_genre mapping.
target_names = [idx_to_genre[i] for i in sorted(idx_to_genre)]
print("\nClassification Report:")
# Generate and print a detailed classification report including precision, recall, and f1-score.
print(classification_report(y_true, y_pred, target_names=target_names))

# Compute the confusion matrix to visualize prediction errors per class.
cm = confusion_matrix(y_true, y_pred)

# Plot the confusion matrix using matplotlib.
plt.figure(figsize=(10, 8))
plt.imshow(cm, interpolation="nearest") # Display the matrix as an image.
plt.title("Confusion Matrix (PyTorch CRNN Bi-GRU)")
plt.colorbar() # Add a color bar to indicate value intensity.
plt.xlabel("Predicted") # Label for the x-axis.
plt.ylabel("True") # Label for the y-axis.
plt.tight_layout() # Adjust plot to prevent labels from overlapping.
plt.show() # Display the plot.

# Spectrogram Transformer-like model

import os
import copy # Used for deep copying model states, essential for saving the best model during training.
import numpy as np
import torch # The core PyTorch library for neural networks.
import torch.nn as nn # PyTorch's module for defining neural network layers.
from torch.utils.data import Dataset, DataLoader # Utilities for creating custom datasets and loading data in batches.

from sklearn.preprocessing import LabelEncoder # For converting categorical labels to numerical format.
from sklearn.metrics import classification_report, confusion_matrix # Tools for evaluating model performance.
import matplotlib.pyplot as plt # For generating plots, such as confusion matrices.

# Encode labels to integers
# Initialize LabelEncoder, which maps string labels (e.g., 'jazz', 'rock') to unique integers.
le = LabelEncoder()
# Fit the encoder on all unique genre labels found across the entire dataset to ensure consistency.
le.fit(np.concatenate([y_train, y_val, y_test]))

# Transform string labels in each dataset split into their numerical integer representations.
y_train_enc = le.transform(y_train)
y_val_enc   = le.transform(y_val)
y_test_enc  = le.transform(y_test)

# Create a dictionary to easily map integer labels back to their original genre names for interpretability.
idx_to_genre = {i: g for i, g in enumerate(le.classes_)}
# Determine the total number of unique classes, which is needed for the model's output layer.
num_classes = len(le.classes_)

print("Classes:", idx_to_genre)

# Convert the feature data (X_train, X_val, X_test) to float32 NumPy arrays.
# Neural networks typically perform computations with float32 for efficiency and compatibility.
X_train_np = X_train.astype(np.float32)
X_val_np   = X_val.astype(np.float32)
X_test_np  = X_test.astype(np.float32)

class MelDataset(Dataset):
    """
    A PyTorch custom Dataset for our Mel-spectrograms.
    It takes preprocessed feature arrays (X) and their corresponding integer labels (y),
    and provides them as PyTorch tensors.
    """
    def __init__(self, X, y):
        # Convert input NumPy arrays to PyTorch tensors.
        # X: Mel-spectrograms, expected shape (N_samples, n_mels, time_frames).
        self.X = torch.from_numpy(X)
        # y: Encoded labels. Using .long() as nn.CrossEntropyLoss expects this type for labels.
        self.y = torch.from_numpy(y).long()

    def __len__(self):
        """Returns the total number of samples in the dataset."""
        return self.X.shape[0]

    def __getitem__(self, idx):
        """
        Retrieves a single Mel-spectrogram and its label by index.
        Returns a tuple (spectrogram_tensor, label_tensor).
        """
        return self.X[idx], self.y[idx]

# Define the batch size for loading data, which determines how many samples are processed at once.
batch_size = 32

# Create instances of the MelDataset for each split (training, validation, testing).
train_ds = MelDataset(X_train_np, y_train_enc)
val_ds   = MelDataset(X_val_np,   y_val_enc)
test_ds  = MelDataset(X_test_np,  y_test_enc)

# Create DataLoader objects for efficient iteration over datasets.
# train_loader: Shuffles data for better generalization during training.
# val_loader, test_loader: No shuffling needed for evaluation.
# num_workers: Number of subprocesses to use for data loading, improving performance.
# pin_memory=True: Transfers data to GPU faster if a GPU is available.
train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)

class SpecPatchEmbedding(nn.Module):
    """
    Converts a 2D spectrogram into a sequence of flattened, linearly embedded patches.
    This is the first step in a Vision Transformer-like architecture for spectrograms.
    """
    def __init__(self, embed_dim=128, patch_size=(16, 16)):
        super().__init__()
        self.patch_h, self.patch_w = patch_size # Height and width of each patch.
        self.embed_dim = embed_dim # The dimension of the embedding vector for each patch.
        # Linear projection layer to embed each flattened patch into 'embed_dim' dimensions.
        self.proj = nn.Linear(self.patch_h * self.patch_w, embed_dim)

    def forward(self, x):
        """
        Forward pass for patch embedding.

        Args:
            x (torch.Tensor): Input spectrogram tensor, shape (B, H, W)
                              where B=batch_size, H=n_mels, W=time_frames.

        Returns:
            torch.Tensor: Embedded patches, shape (B, N_patches, embed_dim).
        """
        B, H, W = x.shape

        # Calculate padding needed to make H and W divisible by patch_h and patch_w.
        pad_h = (self.patch_h - (H % self.patch_h)) % self.patch_h
        pad_w = (self.patch_w - (W % self.patch_w)) % self.patch_w

        # Apply padding if necessary. Pad along the last two dimensions (width then height).
        if pad_h > 0 or pad_w > 0:
            # (padding_left, padding_right, padding_top, padding_bottom)
            x = nn.functional.pad(x, (0, pad_w, 0, pad_h))
            H = H + pad_h # Update height after padding.
            W = W + pad_w # Update width after padding.

        # Reshape the spectrogram into non-overlapping patches.
        # (B, H_patches, patch_h, W_patches, patch_w)
        x = x.view(B, H // self.patch_h, self.patch_h, W // self.patch_w, self.patch_w)
        # Rearrange dimensions to (B, H_patches, W_patches, patch_h, patch_w)
        x = x.permute(0, 1, 3, 2, 4).contiguous()
        # Flatten patches: (B, N_patches, patch_h * patch_w) where N_patches = H_patches * W_patches
        x = x.view(B, (H // self.patch_h) * (W // self.patch_w), self.patch_h * self.patch_w)

        # Project each flattened patch into the embedding dimension.
        x = self.proj(x)  # Result: (B, N_patches, embed_dim)
        return x


class SpectrogramTransformer(nn.Module):
    """
    A Transformer-based model designed for spectrogram classification.
    It processes spectrograms by converting them into sequences of embedded patches,
    adding positional information, and then feeding them through a Transformer Encoder.
    """
    def __init__(self,
                 num_classes,
                 embed_dim=128,      # Dimension for patch embeddings and Transformer layers.
                 patch_size=(16, 16), # Size of square patches to extract from spectrogram.
                 num_layers=4,       # Number of Transformer encoder layers.
                 num_heads=4,        # Number of attention heads in each Transformer layer.
                 ff_dim=256,         # Dimension of the feed-forward network in Transformer layers.
                 dropout=0.1,        # Dropout rate for regularization.
                 max_patches=512):   # Maximum number of patches the model can handle (for positional embedding).
        super().__init__()

        # Step 1: Patch Embedding - Converts spectrogram into a sequence of embedded patches.
        self.patch_embed = SpecPatchEmbedding(embed_dim=embed_dim, patch_size=patch_size)

        # Step 2: Learnable [CLS] token - A special token prepended to the sequence,
        # whose final output state is used for classification (similar to BERT).
        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))

        # Step 3: Positional Embedding - Adds positional information to the patch embeddings,
        # as Transformers are permutation-invariant without it.
        self.pos_embed = nn.Parameter(torch.zeros(1, max_patches + 1, embed_dim)) # +1 for CLS token

        # Step 4: Transformer Encoder - Core of the model, processes the sequence of embedded patches.
        # TransformerEncoderLayer is a single block.
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim,      # Input and output dimension of the layer.
            nhead=num_heads,        # Number of parallel attention heads.
            dim_feedforward=ff_dim, # Dimension of the feed-forward network model.
            dropout=dropout,        # Dropout rate.
            batch_first=True,       # Input/output tensors are (batch, sequence, feature).
            activation="gelu"       # GELU activation function.
        )
        # TransformerEncoder stacks multiple TransformerEncoderLayer instances.
        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        # Step 5: Layer Normalization - Applied before the final classification head.
        self.norm = nn.LayerNorm(embed_dim)

        # Step 6: Classification Head - Takes the [CLS] token's representation and outputs class logits.
        self.head = nn.Sequential(
            nn.Dropout(dropout), # Apply dropout for regularization.
            nn.Linear(embed_dim, num_classes) # Final linear layer maps to the number of output classes.
        )

        # Initialize weights for positional embedding and CLS token.
        nn.init.trunc_normal_(self.pos_embed, std=0.02)
        nn.init.trunc_normal_(self.cls_token, std=0.02)

    def forward(self, x):
        """
        Defines the forward pass of the SpectrogramTransformer model.

        Args:
            x (torch.Tensor): Input spectrograms, shape (B, n_mels, time_frames).

        Returns:
            torch.Tensor: Logits (raw scores) for each class, shape (B, num_classes).
        """
        B = x.size(0) # Get batch size.

        # 1. Apply patch embedding.
        x = self.patch_embed(x)  # Result: (B, N_patches, embed_dim)
        N = x.size(1) # Number of patches.

        # 2. Prepend the learnable [CLS] token to the sequence.
        cls = self.cls_token.expand(B, -1, -1)  # Expand CLS token to match batch size.
        x = torch.cat([cls, x], dim=1)          # Concatenate CLS token with patch embeddings.

        # 3. Add positional embeddings.
        # Check if the number of patches exceeds the maximum allowed by pos_embed.
        if (N + 1) > self.pos_embed.size(1):
            raise ValueError(f"Too many patches ({N}) for max_patches setting. "
                             f"Increase max_patches in the model.")
        x = x + self.pos_embed[:, :N+1, :] # Add relevant portion of positional embeddings.

        # 4. Pass through the Transformer Encoder.
        x = self.encoder(x)      # Result: (B, 1+N_patches, embed_dim)

        # 5. Apply Layer Normalization.
        x = self.norm(x)

        # 6. Extract the [CLS] token's output for classification.
        cls_out = x[:, 0, :]     # The first token in the sequence is the CLS token.

        # 7. Pass through the classification head to get the final logits.
        logits = self.head(cls_out)
        return logits

# Set up the device for computation: use GPU (cuda) if available, otherwise CPU.
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# --- Model Hyperparameters ---
# These parameters can be tuned to optimize model performance.
embed_dim = 128      # Dimension of patch embeddings and Transformer layers.
patch_size = (16, 16) # Size of the patches extracted from the spectrogram.
num_layers = 4       # Number of Transformer encoder blocks.
num_heads = 4        # Number of attention heads in each Transformer block.
ff_dim = 256         # Dimension of the feed-forward network in each Transformer block.
dropout = 0.1        # Dropout rate for regularization.
# Maximum number of patches the model can handle. Calculated based on input spectrogram size (128x130)
# (128/16) * (130/16) ~= 8 * 8.125. With padding, say 8*9 = 72 patches. So 512 is more than enough.
max_patches = 512

# Initialize the SpectrogramTransformer model with the defined hyperparameters.
# Move the model to the selected device (GPU/CPU).
model = SpectrogramTransformer(
    num_classes=num_classes, # Total number of output classes (genres).
    embed_dim=embed_dim,
    patch_size=patch_size,
    num_layers=num_layers,
    num_heads=num_heads,
    ff_dim=ff_dim,
    dropout=dropout,
    max_patches=max_patches
).to(device)

# Define the loss function: CrossEntropyLoss is appropriate for multi-class classification.
criterion = nn.CrossEntropyLoss()
# Define the optimizer: AdamW is a variant of Adam that incorporates weight decay for better regularization.
optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-2)

# Define the file path where the best performing model's state will be saved.
save_path = "/content/drive/My Drive/TUD/Projects/Music Genre Classification/best_spectrogram_transformer.pt"

# --- Early Stopping Configuration ---
patience = 7          # Number of epochs to wait for improvement in validation accuracy before stopping.
best_val_acc = 0.0    # Stores the highest validation accuracy achieved.
epochs_no_improve = 0 # Counter for consecutive epochs without validation accuracy improvement.
best_state = None     # Will store the model's state_dict at the epoch with best_val_acc.

def run_epoch(loader, train=True):
    """
    Executes a single epoch of training or validation/testing for the model.

    Args:
        loader (DataLoader): The DataLoader providing data for the epoch.
        train (bool): True for training mode (enables gradient calculation and weight updates),
                      False for evaluation mode (disables gradients).

    Returns:
        tuple: (average_loss_per_sample, average_accuracy_per_sample) for the epoch.
    """
    # Set the model to training or evaluation mode.
    model.train() if train else model.eval()

    total_loss = 0.0 # Accumulator for total loss.
    correct = 0      # Accumulator for correct predictions.
    total = 0        # Accumulator for total samples processed.

    # Context manager to enable/disable gradient calculation based on 'train' flag.
    with torch.set_grad_enabled(train):
        for xb, yb in loader:
            # Move input features (spectrograms) and labels to the designated device.
            xb = xb.to(device, non_blocking=True)  # (B, n_mels, time)
            yb = yb.to(device, non_blocking=True)

            # Forward pass: get model's predictions (logits).
            logits = model(xb)
            # Calculate the loss.
            loss = criterion(logits, yb)

            if train:
                # Zero previous gradients.
                optimizer.zero_grad()
                # Backpropagate to compute gradients.
                loss.backward()
                # Update model parameters.
                optimizer.step()

            # Accumulate loss and accuracy metrics.
            total_loss += loss.item() * xb.size(0)
            preds = torch.argmax(logits, dim=1) # Get predicted class indices.
            correct += (preds == yb).sum().item()
            total += xb.size(0)

    # Return average loss and accuracy for the epoch.
    return total_loss / total, correct / total

# Define the total number of training epochs.
num_epochs = 100

print("\nStarting Spectrogram Transformer model training...")
# --- Main Training Loop ---
for epoch in range(1, num_epochs + 1):
    # Run training phase for one epoch.
    train_loss, train_acc = run_epoch(train_loader, train=True)
    # Run validation phase for one epoch.
    val_loss, val_acc     = run_epoch(val_loader, train=False)

    # Print current epoch's results.
    print(f"Epoch {epoch:02d}/{num_epochs} "
          f"train_loss={train_loss:.4f} train_acc={train_acc:.4f} "
          f"val_loss={val_loss:.4f} val_acc={val_acc:.4f}")

    # --- Check for Best Model and Save ---
    # If current validation accuracy is an improvement:
    if val_acc > best_val_acc:
        best_val_acc = val_acc # Update best accuracy.
        best_state = copy.deepcopy(model.state_dict()) # Deep copy the model's weights.
        torch.save(best_state, save_path) # Save the best model state to file.
        print(f"  Saved best model to: {save_path}")
        epochs_no_improve = 0 # Reset early stopping counter.
    else:
        epochs_no_improve += 1 # Increment counter if no improvement.

    # --- Early Stopping Check ---
    # If validation accuracy hasn't improved for 'patience' epochs, stop training.
    if epochs_no_improve >= patience:
        print(f"Early stopping triggered. Best val_acc={best_val_acc:.4f}")
        break # Exit the training loop.

# After training, load the weights of the best performing model.
model.load_state_dict(torch.load(save_path, map_location=device))
print("Loaded best model from:", save_path)
print("Spectrogram Transformer model training complete.")

# Set the model to evaluation mode. This disables dropout and batch normalization updates.
model.eval()

# Initialize lists to store all predictions and true labels from the test set.
all_preds = []
all_true = []

# Disable gradient calculations during evaluation to save memory and speed up computation.
with torch.no_grad():
    # Iterate over the test data loader.
    for xb, yb in test_loader:
        # Move the input features (xb) to the appropriate device (GPU/CPU).
        xb = xb.to(device, non_blocking=True)

        # Perform a forward pass to get the model's predictions (logits).
        logits = model(xb)
        # Get the predicted class by finding the index of the maximum logit, then move to CPU and convert to NumPy.
        preds = torch.argmax(logits, dim=1).cpu().numpy()

        # Append the predictions and true labels (converted to NumPy) to their respective lists.
        all_preds.append(preds)
        all_true.append(yb.numpy())

# Concatenate all predictions and true labels from batches into single NumPy arrays.
y_pred = np.concatenate(all_preds)
y_true = np.concatenate(all_true)

# Calculate the overall test accuracy.
test_acc = (y_pred == y_true).mean()
print(f"Test Accuracy (Spectrogram Transformer): {test_acc:.4f}")

# Prepare target names for the classification report using our idx_to_genre mapping.
target_names = [idx_to_genre[i] for i in sorted(idx_to_genre)]
print("\nClassification Report:")
# Generate and print a detailed classification report including precision, recall, and f1-score.
print(classification_report(y_true, y_pred, target_names=target_names))

# Compute the confusion matrix to visualize prediction errors per class.
cm = confusion_matrix(y_true, y_pred)

# Plot the confusion matrix using matplotlib.
plt.figure(figsize=(10, 8))
plt.imshow(cm, interpolation="nearest") # Display the matrix as an image.
plt.title("Confusion Matrix (Spectrogram Transformer)")
plt.colorbar() # Add a color bar to indicate value intensity.
plt.xlabel("Predicted") # Label for the x-axis.
plt.ylabel("True") # Label for the y-axis.
plt.tight_layout() # Adjust plot to prevent labels from overlapping.
plt.show() # Display the plot.

# To prepare our environment for the Audio Spectrogram Transformer (AST) model,
# we need to install a few extra dependencies.
# First, we update our package lists and install 'ffmpeg'. ffmpeg is a crucial tool
# for handling various audio and video formats, often required by audio processing libraries.
!apt-get -qq update
!apt-get -qq install -y ffmpeg

# Next, we install Python packages using pip:
# - soundfile: A library for reading and writing sound files.
# - transformers: Hugging Face's library, providing pre-trained models like AST.
# - torchaudio: PyTorch's audio library, used for advanced audio I/O and processing.
# - torchcodec: A Python library for audio and video encoding/decoding.
!pip -q install soundfile transformers torchaudio torchcodec

import os, copy, numpy as np # Standard imports for file operations, copying, and numerical computations.
import torch # The core PyTorch library for building neural networks.
import torch.nn as nn # Neural network layers and modules from PyTorch.
from torch.utils.data import Dataset, DataLoader # Utilities for creating custom datasets and loading data in batches.

import torchaudio # PyTorch's library specifically for audio processing.
from transformers import ASTFeatureExtractor, ASTForAudioClassification # Hugging Face's modules for AST: feature extraction and the model itself.

from sklearn.preprocessing import LabelEncoder # For converting categorical text labels to numerical IDs.
from sklearn.metrics import classification_report, confusion_matrix # For evaluating model performance after training.
import matplotlib.pyplot as plt # For plotting results, like confusion matrices.

# Determine the device to use for computations (GPU if available, otherwise CPU).
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# --- Label Encoding for AST Model ---
# Initialize the LabelEncoder to convert our genre names (strings) into numerical labels.
# This is a prerequisite for training most classification models.
le = LabelEncoder()
# Fit the encoder using all labels from the training, validation, and test sets.
# This ensures a consistent mapping for all possible genres across the dataset.
le.fit(np.concatenate([train_labels, val_labels, test_labels]))

# Transform the string labels in each dataset split into their numerical integer representations.
y_train_enc = le.transform(train_labels)
y_val_enc   = le.transform(val_labels)
y_test_enc  = le.transform(test_labels)

# Create a dictionary to map the encoded integer labels back to human-readable genre names.
# This is invaluable for interpreting model predictions and evaluation reports.
idx_to_genre = {i: g for i, g in enumerate(le.classes_)}
# Get the total number of unique classes, which is needed to configure the final output layer of the model.
num_classes = len(le.classes_)
print("Classes:", idx_to_genre)

# Define target sample rate for audio processing. AST models are typically trained on 16kHz audio.
TARGET_SR = 16000
# Define the maximum duration of an audio segment in seconds.
MAX_SECONDS = 10
# Calculate the total number of samples for the fixed maximum duration.
MAX_SAMPLES = TARGET_SR * MAX_SECONDS

# Note: The line `torchaudio.set_audio_backend("soundfile")` has been removed
# because `set_audio_backend` is deprecated in recent versions of torchaudio.
# torchaudio now often auto-detects available backends (like ffmpeg, which we installed).

def load_audio_torchaudio(path, target_sr=TARGET_SR):
    """
    Loads an audio file using torchaudio, resamples it if necessary, and converts it to mono.
    Returns the audio as a 1D float32 NumPy array, or None if loading fails.
    """
    try:
        # Load audio file. `wav` will be a tensor of shape (channels, num_samples).
        wav, sr = torchaudio.load(path)
        # Convert stereo to mono by taking the mean across channels.
        wav = wav.mean(dim=0)
        # Resample the audio to the target sample rate if it's different.
        if sr != target_sr:
            wav = torchaudio.functional.resample(wav, sr, target_sr)
        # Convert the PyTorch tensor to a NumPy array of float32.
        return wav.numpy().astype(np.float32)
    except Exception as e:
        # Print an error message if audio loading fails for any reason.
        print(f"Error loading audio {path}: {e}")
        return None # Return None to indicate failure.


class AudioPathDataset(Dataset):
    """
    A PyTorch Dataset class that loads audio files from their paths on-the-fly.
    It handles audio loading, resampling, and padding/trimming to a fixed length.
    """
    def __init__(self, paths, labels_enc):
        # Store the file paths and their corresponding encoded labels.
        self.paths = np.array(paths)
        self.labels = np.array(labels_enc)

    def __len__(self):
        """Returns the total number of audio files in the dataset."""
        return len(self.paths)

    def __getitem__(self, idx):
        """
        Retrieves a single processed audio sample and its label by index.
        Returns (audio_array, label) or None if the audio file cannot be loaded.
        """
        path = str(self.paths[idx]) # Get the file path for the current index.
        y = int(self.labels[idx])   # Get the integer label.

        # Load and preprocess the audio using our helper function.
        audio = load_audio_torchaudio(path, TARGET_SR)

        # If audio loading failed or resulted in an empty array, return None.
        if audio is None or audio.size == 0:
            return None

        # Pad or trim the audio to ensure it has a fixed length (MAX_SAMPLES).
        if len(audio) < MAX_SAMPLES:
            # Pad with zeros if the audio is shorter than MAX_SAMPLES.
            audio = np.pad(audio, (0, MAX_SAMPLES - len(audio)), mode="constant")
        else:
            # Trim if the audio is longer than MAX_SAMPLES.
            audio = audio[:MAX_SAMPLES]

        return audio, y

# Initialize the feature extractor from a pre-trained Audio Spectrogram Transformer (AST) model.
# This extractor converts raw audio waveforms into Mel-spectrograms in a format suitable for the AST model.
feature_extractor = ASTFeatureExtractor.from_pretrained("MIT/ast-finetuned-audioset-10-10-0.4593")

def collate_fn(batch):
    """
    Custom collation function for our DataLoader.
    This function processes a batch of (audio, label) pairs.
    It's responsible for extracting features from the audio and stacking them into a single tensor.
    """
    # Filter out any 'None' entries in the batch, which might result from failed audio loading.
    batch = [b for b in batch if b is not None]
    # If the batch becomes empty after filtering, return None to indicate an invalid batch.
    if len(batch) == 0:
        return None  # The caller (training loop) must handle this.

    # Separate audio samples and labels from the valid batch entries.
    audios, labels = zip(*batch)

    # Use the AST feature extractor to process the raw audio waveforms.
    # It will convert them into Mel-spectrograms and return them as PyTorch tensors.
    inputs = feature_extractor(list(audios), sampling_rate=TARGET_SR, return_tensors="pt")

    # The exact key for the input features might vary slightly depending on the transformers version.
    # We check for 'input_values' first, then 'input_features'.
    if "input_values" in inputs:
        x = inputs["input_values"]
    else:
        x = inputs["input_features"]

    # Convert labels to a PyTorch tensor with a Long data type, as expected by CrossEntropyLoss.
    y = torch.tensor(labels, dtype=torch.long)

    return x, y

# Set a relatively small batch size for the AST model, as it can be memory-intensive.
batch_size = 8  # AST is heavy

# Create instances of our custom AudioPathDataset for training, validation, and testing.
# These datasets will load audio files on-the-fly and preprocess them.
train_ds = AudioPathDataset(train_paths, y_train_enc)
val_ds   = AudioPathDataset(val_paths,   y_val_enc)
test_ds  = AudioPathDataset(test_paths,  y_test_enc)

# Create DataLoader instances for each dataset.
# num_workers=0 is used here, which means the data loading will happen in the main process.
# This is often done when debugging or when `collate_fn` involves processes that conflict with multiprocessing.
# The `collate_fn` we defined earlier is crucial here to handle feature extraction and batching.
train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=0, collate_fn=collate_fn)
val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)
test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)

# Initialize the Audio Spectrogram Transformer (AST) model for audio classification.
# We're loading a pre-trained model ('MIT/ast-finetuned-audioset-10-10-0.4593')
# and adapting its final classification layer to our specific number of genres (num_labels=num_classes).
# `ignore_mismatched_sizes=True` is used because the original model's head has a different output size (527 classes for AudioSet)
# than our 10 genre classes, so we're replacing that layer.
model = ASTForAudioClassification.from_pretrained(
    "MIT/ast-finetuned-audioset-10-10-0.4593",
    num_labels=num_classes,
    ignore_mismatched_sizes=True
).to(device) # Move the model to the selected device (GPU/CPU).

# Define the loss function: CrossEntropyLoss is standard for multi-class classification.
criterion = nn.CrossEntropyLoss()
# Define the optimizer: AdamW is used with a small learning rate suitable for fine-tuning pre-trained models,
# and weight_decay for regularization to prevent overfitting.
optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-2)

# Define the path where the best performing AST model's weights will be saved.
save_path = "/content/drive/My Drive/TUD/Projects/Music Genre Classification/best_ast_transformer.pt"

# --- Early Stopping Configuration ---
patience = 5          # Number of epochs to wait for validation accuracy improvement.
best_val_acc = 0.0    # Keeps track of the highest validation accuracy.
epochs_no_improve = 0 # Counter for consecutive epochs without improvement.

def run_epoch(loader, train=True):
    """
    Executes a single epoch of training or validation/testing for the AST model.

    Args:
        loader (DataLoader): The DataLoader for the current epoch.
        train (bool): True for training mode, False for evaluation mode.

    Returns:
        tuple: (average_loss_per_sample, average_accuracy_per_sample) for the epoch.
    """
    # Set model to training or evaluation mode.
    model.train() if train else model.eval()
    total_loss, correct, total = 0.0, 0, 0

    with torch.set_grad_enabled(train):
        for batch in loader:
            # Handle cases where `collate_fn` might return None (e.g., all samples in batch failed to load).
            if batch is None:
                continue

            xb, yb = batch
            # Move input features and labels to the device.
            xb = xb.to(device, non_blocking=True)
            yb = yb.to(device, non_blocking=True)

            # Forward pass: the AST model expects `input_values` for spectrogram features.
            out = model(input_values=xb)
            logits = out.logits # Extract logits from the model's output.
            loss = criterion(logits, yb)

            if train:
                optimizer.zero_grad() # Clear previous gradients.
                loss.backward()       # Compute gradients.
                # Clip gradients to prevent exploding gradients, which can be common in Transformers.
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()      # Update model parameters.

            # Accumulate metrics.
            total_loss += loss.item() * xb.size(0)
            preds = torch.argmax(logits, dim=1)
            correct += (preds == yb).sum().item()
            total += xb.size(0)

    # If no samples were processed (e.g., all batches were None), return infinite loss and zero accuracy.
    if total == 0:
        return float("inf"), 0.0

    return total_loss / total, correct / total


# Define the total number of epochs for fine-tuning.
num_epochs = 20

print("\nStarting AST Transformer model fine-tuning...")
# --- Main Fine-tuning Loop ---
for epoch in range(1, num_epochs + 1):
    # Run training and validation for the current epoch.
    train_loss, train_acc = run_epoch(train_loader, train=True)
    val_loss, val_acc     = run_epoch(val_loader, train=False)

    # Print epoch results.
    print(f"Epoch {epoch:02d}/{num_epochs} "
          f"train_loss={train_loss:.4f} train_acc={train_acc:.4f} "
          f"val_loss={val_loss:.4f} val_acc={val_acc:.4f}")

    # --- Check for Best Model and Save ---
    # If current validation accuracy is better than the best recorded so far.
    if val_acc > best_val_acc:
        best_val_acc = val_acc # Update the best validation accuracy.
        # Save the model's state dictionary to the specified path.
        torch.save(model.state_dict(), save_path)
        print(f"  Saved best model to: {save_path}")
        epochs_no_improve = 0 # Reset the early stopping counter.
    else:
        epochs_no_improve += 1 # Increment the counter if no improvement.

    # --- Early Stopping Check ---
    # If `epochs_no_improve` reaches `patience`, stop training.
    if epochs_no_improve >= patience:
        print(f"Early stopping. Best val_acc={best_val_acc:.4f}")
        break # Exit the training loop.

# After the loop, load the best performing model weights from the saved file.
model.load_state_dict(torch.load(save_path, map_location=device))
print("Loaded best model from:", save_path)
print("AST Transformer model fine-tuning complete.")

# Set the model to evaluation mode. This deactivates features like dropout layers
# and ensures that batch normalization layers use their learned statistics.
model.eval()

# Initialize lists to collect all predictions and true labels from the test set.
all_preds = []
all_true = []

# Disable gradient calculations during evaluation. This saves memory and computation time,
# as we don't need to update model weights during testing.
with torch.no_grad():
    # Iterate through the test data loader, getting batches of spectrograms (xb) and true labels (yb).
    for xb, yb in test_loader:
        # Move the input batch (xb) to the appropriate device (GPU/CPU) for computation.
        xb = xb.to(device, non_blocking=True)

        # Perform a forward pass through the model to get raw prediction scores (logits).
        # The `model` object from Hugging Face's `transformers` library returns an output object,
        # and the `logits` are accessed via `.logits` attribute.
        logits = model(xb).logits
        # Determine the predicted class by finding the index with the highest logit score for each sample.
        # Move the predictions back to the CPU and convert them to a NumPy array.
        preds = torch.argmax(logits, dim=1).cpu().numpy()

        # Append the current batch's predictions and true labels to our collecting lists.
        all_preds.append(preds)
        all_true.append(yb.numpy())

# Concatenate all collected predictions and true labels into single NumPy arrays
# for comprehensive evaluation.
y_pred = np.concatenate(all_preds)
y_true = np.concatenate(all_true)

# Calculate the overall test accuracy by comparing predicted labels to true labels.
test_acc = (y_pred == y_true).mean()
print(f"Test Accuracy (Spectrogram Transformer): {test_acc:.4f}")

# Prepare the target names (genre names) for the classification report.
# We retrieve them from our `idx_to_genre` mapping, ensuring they are sorted by index.
target_names = [idx_to_genre[i] for i in sorted(idx_to_genre)]
print("\nClassification Report:")
# Generate and print a detailed classification report, which includes precision, recall, and F1-score
# for each class, as well as overall averages.
print(classification_report(y_true, y_pred, target_names=target_names))

# Compute the confusion matrix. This matrix shows the number of correct and incorrect predictions
# for each class, providing insights into specific misclassifications.
cm = confusion_matrix(y_true, y_pred)

# Plot the confusion matrix using Matplotlib.
plt.figure(figsize=(10, 8))
plt.imshow(cm, interpolation="nearest") # Display the matrix as an image with 'nearest' interpolation for sharp pixels.
plt.title("Confusion Matrix (Spectrogram Transformer)") # Set the title of the plot.
plt.colorbar() # Add a color bar to indicate the scale of values in the matrix.
plt.xlabel("Predicted") # Label for the x-axis (predicted classes).
plt.ylabel("True") # Label for the y-axis (true classes).
plt.tight_layout() # Adjust the plot to ensure all elements fit without overlapping.
plt.show() # Display the generated plot.